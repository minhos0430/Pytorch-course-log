{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7uMZlYvNB1sc",
        "outputId": "710a49d1-3f47-4702-ad87-a0f74aa6fbed"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time to learn pytorch\n"
          ]
        }
      ],
      "source": [
        "#just python basics\n",
        "print(\"time to learn pytorch\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WrPVKaaHCChj",
        "outputId": "68d2eec3-bbec-4561-efb3-fda1b8690d80"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sun Jan  4 16:40:54 2026       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n",
            "| N/A   36C    P8              9W /   70W |       0MiB /  15360MiB |      0%      Default |\n",
            "|                                         |                        |                  N/A |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "|  No running processes found                                                             |\n",
            "+-----------------------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "print(torch.__version__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SWa4g96dCG0k",
        "outputId": "41e024e4-d9fd-4f6f-dd54-559ca9a7ecde"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.9.0+cu126\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#tensors are a generalization of a data structures like scalar, vectors, matrices so we don't change their names due to their dimensionality\n",
        "#creating tensors\n",
        "scalar = torch.tensor(7)\n",
        "scalar"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "94OZfLUrFiah",
        "outputId": "79f4b410-45c1-4dce-c827-3211ae7d3fab"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(7)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "scalar.ndim"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T9m3JaOIFxgY",
        "outputId": "0cc41acc-f8c6-4056-b443-cbca83103788"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "scalar.item()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vWJQM8OyGvuX",
        "outputId": "31c4b052-695e-41e0-ae82-2245c077c081"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "7"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vector = torch.tensor([2,2])\n",
        "print(vector.ndim)\n",
        "print(vector.shape)\n",
        "print(vector)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p8hzaHieGxYO",
        "outputId": "287a5c93-61d6-4cc1-8a9e-5b02184236a8"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1\n",
            "torch.Size([2])\n",
            "tensor([2, 2])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Matrix and tensors. Matrices are just 2 dimensional tensors as tensors are the generalized term for n dimensional data structures\n",
        "matrix = torch.tensor([[7,8],[2,3],[3,4]])\n",
        "print(matrix.ndim)\n",
        "print(matrix.shape)\n",
        "print(matrix)\n",
        "matrix2 = torch.tensor([[1,2],[3,4]])\n",
        "print(matrix2.ndim)\n",
        "print(matrix2.shape)\n",
        "print(matrix2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "abHjfEWQfOEB",
        "outputId": "237d8502-7875-44dc-883a-12644bc0f372"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2\n",
            "torch.Size([3, 2])\n",
            "tensor([[7, 8],\n",
            "        [2, 3],\n",
            "        [3, 4]])\n",
            "2\n",
            "torch.Size([2, 2])\n",
            "tensor([[1, 2],\n",
            "        [3, 4]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tensor = torch.tensor([[[1,2,3],[2,3,4],[2,3,4]]])\n",
        "print(tensor.ndim)\n",
        "print(tensor.shape)\n",
        "print(tensor)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h0aXFAPZHULN",
        "outputId": "342a7bd1-2b3c-4d53-a39d-d8b749060c31"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3\n",
            "torch.Size([1, 3, 3])\n",
            "tensor([[[1, 2, 3],\n",
            "         [2, 3, 4],\n",
            "         [2, 3, 4]]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#One of the common pitfalls apparently is that we access the wrong rank of our tensor\n",
        "print(tensor[0])\n",
        "#compare that with\n",
        "print('\\n')\n",
        "print(tensor[0][0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_BdL82cHHp2U",
        "outputId": "e4b3c884-a80a-46a3-97a6-29dda7ff6a19"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1, 2, 3],\n",
            "        [2, 3, 4],\n",
            "        [2, 3, 4]])\n",
            "\n",
            "\n",
            "tensor([1, 2, 3])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "random_tensor = torch.rand(3,4)\n",
        "#create a random tensor with 3 rows and 4 columns\n",
        "#useful for the starting tensors for neural networks.\n",
        "print(random_tensor)"
      ],
      "metadata": {
        "id": "4dGZtRRFH_0E",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "63c22fda-0a74-465d-9fee-d5d9968d0b22"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.3927, 0.3696, 0.2150, 0.1285],\n",
            "        [0.5204, 0.7215, 0.7642, 0.2362],\n",
            "        [0.1708, 0.4326, 0.7352, 0.9223]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## zeroes and ones, zeroes is useful to mask bits\n",
        "zero = torch.zeros(3,1)\n",
        "print(zero * random_tensor)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H6tWbmwvTZ25",
        "outputId": "c0391b23-0626-4be6-c64e-517a231c1e92"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#ones explanation was skipped as they're solemnly used\n",
        "ones = torch.ones(3,4)"
      ],
      "metadata": {
        "id": "vvVUyXXRTzfH"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "one_to_ten = torch.arange(1,11,1) #it takes, start, end, steps, it's similar to the range() function in python\n",
        "one_to_ten"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JERF_ZKKX1Nl",
        "outputId": "340ce384-4a85-400b-ae27-90dd3e8aa9e1"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10])"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#tensors.'x'_like method returns a ones or zeroes  tensor that has the same shape as the input tensor with the values there.\n",
        "zeroeslike = torch.zeros_like(one_to_ten)\n",
        "zeroeslike"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mlQYCkNVX3tl",
        "outputId": "40e33c10-b68f-4332-b490-196b4f7b5fae"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#tensors with specific datatypes, the tensor creating methods take in the dtype argument to specify the dtype. The specific name for the dtypes you can just look up\n",
        "float32tensor = torch.tensor([[3.0,34,3.3],[23,4,4]],\n",
        "                             dtype = None,\n",
        "                             device=None,\n",
        "                             requires_grad=False)\n",
        "float32tensor.dtype"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6T5vR3AZYg2I",
        "outputId": "5758f30c-2b1b-4ce4-b2ca-5ce33f7a6e0a"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.float32"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Big 3 Errors we'll probably run in with Tensor Attributes\n",
        "1. tensors with not the right datatype (verify with tensor.dtype)\n",
        "2. tensors not right shape (verify with tensor.shape)\n",
        "3. tensors not on right device (verify with tensor.device)\n",
        "\n",
        "\n",
        "##other things\n",
        "1. surprisingly a lot of int * floats do work but we just have to know that this could cause issues\n",
        "2. devices refer to GPU and CPU"
      ],
      "metadata": {
        "id": "QY__NdcvgDNM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#we can typecase tensors using the following. 'tensorname.type(dtype)'\n",
        "float16 = float32tensor.type(torch.float16)\n",
        "float16.dtype\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bHRpguIwY-Fk",
        "outputId": "1cd79b9d-e6d1-4824-f094-3d80bc35febf"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.float16"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "float16.device\n",
        "float16.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tg7i75F4gyuj",
        "outputId": "9bb63087-060e-4c92-cc03-b3f82ec2d1c9"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([2, 3])"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Operations\n",
        "add, sub, multiply(element wise), divide, matrix multiplication.\n",
        "total of 5 multiplications. Matrix multiplication and normal multiplication depend on the rank of the tensor.\n",
        ". if we add/sub/multiply/divide a tensor it will do the operation so for all elements. So there goes 4 cases.\n",
        ". Matrix Multiplications are matrix multiplications/dot products are shown in the second cell below"
      ],
      "metadata": {
        "id": "otQL2il6rbVy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#operations are done twice to show diff ways of doing so\n",
        "tensor = torch.arange(0,6)\n",
        "print(tensor)\n",
        "print('\\n')\n",
        "print(tensor +10)\n",
        "print(torch.add(tensor,10))\n",
        "print('\\n')\n",
        "print(tensor -10)\n",
        "print(torch.sub(tensor,10))\n",
        "print('\\n')\n",
        "print(tensor *10)\n",
        "print(torch.mul(tensor,10))\n",
        "print('\\n')\n",
        "print(tensor /10)\n",
        "print(torch.div(tensor,10))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vKcgjh5wtHqw",
        "outputId": "61fc7927-60ab-4ed9-9cae-80560d98e9cf"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0, 1, 2, 3, 4, 5])\n",
            "\n",
            "\n",
            "tensor([10, 11, 12, 13, 14, 15])\n",
            "tensor([10, 11, 12, 13, 14, 15])\n",
            "\n",
            "\n",
            "tensor([-10,  -9,  -8,  -7,  -6,  -5])\n",
            "tensor([-10,  -9,  -8,  -7,  -6,  -5])\n",
            "\n",
            "\n",
            "tensor([ 0, 10, 20, 30, 40, 50])\n",
            "tensor([ 0, 10, 20, 30, 40, 50])\n",
            "\n",
            "\n",
            "tensor([0.0000, 0.1000, 0.2000, 0.3000, 0.4000, 0.5000])\n",
            "tensor([0.0000, 0.1000, 0.2000, 0.3000, 0.4000, 0.5000])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#dot products/matrix multiplications are done in pytorch using the following\n",
        "matrixA = torch.tensor([[1,2,3,4,5],[1,2,3,4,5]])\n",
        "matrixB = torch.tensor([[1,2],\n",
        "                        [3,4],\n",
        "                        [5,6],\n",
        "                        [7,8],\n",
        "                        [9,0]])\n",
        "\n",
        "print(matrixA.shape,matrixB.shape)\n",
        "print('See how inner dimensions match but the shape is from the outer dimensions, that must follow broadcasting rules ')\n",
        "print('\\n')\n",
        "print(torch.matmul(matrixA,matrixB)) #this is matrix multiplication\n",
        "print(torch.mm(matrixA,matrixB)) #this is matrix multiplication\n",
        "print(matrixA @ matrixB) #this is matrix multiplication"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Asry2CareK2",
        "outputId": "f9c75920-680c-459c-ff9c-ecfd42aceb19"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([2, 5]) torch.Size([5, 2])\n",
            "See how inner dimensions match but the shape is from the outer dimensions, that must follow broadcasting rules \n",
            "\n",
            "\n",
            "tensor([[95, 60],\n",
            "        [95, 60]])\n",
            "tensor([[95, 60],\n",
            "        [95, 60]])\n",
            "tensor([[95, 60],\n",
            "        [95, 60]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "print(torch.matmul(matrixA,matrixB)) #this is matrix multiplication"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LKbX1l8dx9V_",
        "outputId": "bb3d9124-af8c-4385-dc96-10ef720184b9"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[95, 60],\n",
            "        [95, 60]])\n",
            "CPU times: user 823 µs, sys: 120 µs, total: 943 µs\n",
            "Wall time: 764 µs\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "print(matrixA @ matrixB) #this is matrix multiplication"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P1JNJZw9x_D2",
        "outputId": "20123313-aacf-4a62-8c40-79812129d0c3"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[95, 60],\n",
            "        [95, 60]])\n",
            "CPU times: user 394 µs, sys: 896 µs, total: 1.29 ms\n",
            "Wall time: 1.76 ms\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Seems lilke using @ or matmul makes little difference on the time."
      ],
      "metadata": {
        "id": "CUpTDbmdyI2j"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Just as a easy heuristic for shape mismatch errors:\n",
        "1. use .shape() and the shapes of the inner dimensions must match, in addition the outer dimensions will determine the shape of the matrix\n",
        "2. If we have 2 tensors of the same shape, take the transpose of 1 to multiply them. This is shown below"
      ],
      "metadata": {
        "id": "87pwokfry0oO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "matrixC = torch.rand(3,4)\n",
        "matrixD = torch.rand(3,4)\n",
        "print(f'matrix C is {matrixC}')\n",
        "print(f'matrix D is {matrixD}')\n",
        "print('\\n')\n",
        "#print(matrixC @ matrixD) <<--- causes error\n",
        "matrixD2 = matrixD.T\n",
        "print(f'multiplied we have {matrixC @ matrixD2} because we took the transpose of D')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Giypax04zHFD",
        "outputId": "d11cdea3-893f-4038-a641-d97da431967b"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "matrix C is tensor([[0.4095, 0.5138, 0.8089, 0.9733],\n",
            "        [0.9166, 0.1837, 0.5434, 0.8315],\n",
            "        [0.9144, 0.7061, 0.8320, 0.8387]])\n",
            "matrix D is tensor([[0.6526, 0.9107, 0.4113, 0.6277],\n",
            "        [0.5294, 0.3666, 0.6312, 0.4884],\n",
            "        [0.2552, 0.1025, 0.1195, 0.3613]])\n",
            "\n",
            "\n",
            "multiplied we have tensor([[1.6789, 1.3912, 0.6055],\n",
            "        [1.5109, 1.3018, 0.6181],\n",
            "        [2.1085, 1.6778, 0.7081]]) because we took the transpose of D\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Finding Tensor's Descriptive statistics (min, max,  mean, sum etc) + aggregation"
      ],
      "metadata": {
        "id": "THwHURLKhKDa"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2SFLbzpgpo3R"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.arange(0,100,10)"
      ],
      "metadata": {
        "id": "o5Mp2CWGhZI_"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## .min .max .sum .mean all work, below are different ways to use them. note that mean only works on Long datatypes in torch.  "
      ],
      "metadata": {
        "id": "fSjiwi0Pp2Vr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(x.min(), torch.min(x), x.max(), torch.max(x), x.type(torch.float32).mean(), torch.mean(x.type(torch.float32)), x.sum(), torch.sum(x))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v1OGgnq5jV__",
        "outputId": "9c13792f-f9e2-4533-c1c1-c742d18d5d46"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0) tensor(0) tensor(90) tensor(90) tensor(45.) tensor(45.) tensor(450) tensor(450)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## argmin and argmax finds the smallest and largets values' positions, useful for softmax layers"
      ],
      "metadata": {
        "id": "8_IOTrLvqIYD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(x.argmin(), x.argmax())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6yhA1cRXp1as",
        "outputId": "e370a879-88d0-4c8a-a24a-0956962da767"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0) tensor(9)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Reshaping, Viewing, Stacking, Squeezing, Permuting Tensors\n",
        "1. reshaping reshapes a tensors' dimensions (for matrix mult)\n",
        "2. viewing prints the tensor in a given shape but doesn't change it in memory, but assigning a variable to a view of a  tensor makes the variable point to the tensor in memory.\n",
        "3. Stacking stacks tensors vertically or horizontally, hence vstack and hstack\n",
        "4. Squeezing removes all '1' dimensions in a tensor\n",
        "5. Unqueezing adds a '1' dimension\n",
        "6. Permute prints a tensor with permuted (swapped) dimensions, using permute also references the original tensor\n"
      ],
      "metadata": {
        "id": "zUP1gLr6qcbV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "t  = torch.arange(1,101)\n",
        "t_reshaped = t.reshape(1,10,10) #remember, just like pandas, tensor dimensions must be compatible. A good rule of thumb is factors of the tocal dimensions\n",
        "print(t_reshaped)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HPmqcA6sqTzN",
        "outputId": "fecd244d-bbb1-4aac-9825-0bd01ae5301e"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[  1,   2,   3,   4,   5,   6,   7,   8,   9,  10],\n",
            "         [ 11,  12,  13,  14,  15,  16,  17,  18,  19,  20],\n",
            "         [ 21,  22,  23,  24,  25,  26,  27,  28,  29,  30],\n",
            "         [ 31,  32,  33,  34,  35,  36,  37,  38,  39,  40],\n",
            "         [ 41,  42,  43,  44,  45,  46,  47,  48,  49,  50],\n",
            "         [ 51,  52,  53,  54,  55,  56,  57,  58,  59,  60],\n",
            "         [ 61,  62,  63,  64,  65,  66,  67,  68,  69,  70],\n",
            "         [ 71,  72,  73,  74,  75,  76,  77,  78,  79,  80],\n",
            "         [ 81,  82,  83,  84,  85,  86,  87,  88,  89,  90],\n",
            "         [ 91,  92,  93,  94,  95,  96,  97,  98,  99, 100]]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tv = t.view(10,1,10)\n",
        "tv"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F1u2mzFism-9",
        "outputId": "e4f256a2-e0f7-4eba-d1f2-4717763f53cd"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[  1,   2,   3,   4,   5,   6,   7,   8,   9,  10]],\n",
              "\n",
              "        [[ 11,  12,  13,  14,  15,  16,  17,  18,  19,  20]],\n",
              "\n",
              "        [[ 21,  22,  23,  24,  25,  26,  27,  28,  29,  30]],\n",
              "\n",
              "        [[ 31,  32,  33,  34,  35,  36,  37,  38,  39,  40]],\n",
              "\n",
              "        [[ 41,  42,  43,  44,  45,  46,  47,  48,  49,  50]],\n",
              "\n",
              "        [[ 51,  52,  53,  54,  55,  56,  57,  58,  59,  60]],\n",
              "\n",
              "        [[ 61,  62,  63,  64,  65,  66,  67,  68,  69,  70]],\n",
              "\n",
              "        [[ 71,  72,  73,  74,  75,  76,  77,  78,  79,  80]],\n",
              "\n",
              "        [[ 81,  82,  83,  84,  85,  86,  87,  88,  89,  90]],\n",
              "\n",
              "        [[ 91,  92,  93,  94,  95,  96,  97,  98,  99, 100]]])"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#here's an example of stack.\n",
        "tstack = torch.stack([t,t,t,t],dim=0)\n",
        "t"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5lqkZQEms-Iz",
        "outputId": "1e0197d6-af87-4fe3-9308-1d6b007db91a"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([  1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,  14,\n",
              "         15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,  28,\n",
              "         29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,  42,\n",
              "         43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,  56,\n",
              "         57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,  70,\n",
              "         71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,  84,\n",
              "         85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,  98,\n",
              "         99, 100])"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#here's squeeze and unsqueeze\n",
        "#t_reshaped is our tensor that's dimension 1,10,10\n",
        "print(t_reshaped)\n",
        "print('Here\\'s t_reshaped squeezed\\n')\n",
        "print(t_reshaped.squeeze())\n",
        "print('Here\\'s t_reshaped unsqueezed\\n')\n",
        "print(t_reshaped.unsqueeze(dim=0))\n",
        "#"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6YguCEDgtqAO",
        "outputId": "f3f58915-5773-45d4-9104-5938e4587d03"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[  1,   2,   3,   4,   5,   6,   7,   8,   9,  10],\n",
            "         [ 11,  12,  13,  14,  15,  16,  17,  18,  19,  20],\n",
            "         [ 21,  22,  23,  24,  25,  26,  27,  28,  29,  30],\n",
            "         [ 31,  32,  33,  34,  35,  36,  37,  38,  39,  40],\n",
            "         [ 41,  42,  43,  44,  45,  46,  47,  48,  49,  50],\n",
            "         [ 51,  52,  53,  54,  55,  56,  57,  58,  59,  60],\n",
            "         [ 61,  62,  63,  64,  65,  66,  67,  68,  69,  70],\n",
            "         [ 71,  72,  73,  74,  75,  76,  77,  78,  79,  80],\n",
            "         [ 81,  82,  83,  84,  85,  86,  87,  88,  89,  90],\n",
            "         [ 91,  92,  93,  94,  95,  96,  97,  98,  99, 100]]])\n",
            "Here's t_reshaped squeezed\n",
            "\n",
            "tensor([[  1,   2,   3,   4,   5,   6,   7,   8,   9,  10],\n",
            "        [ 11,  12,  13,  14,  15,  16,  17,  18,  19,  20],\n",
            "        [ 21,  22,  23,  24,  25,  26,  27,  28,  29,  30],\n",
            "        [ 31,  32,  33,  34,  35,  36,  37,  38,  39,  40],\n",
            "        [ 41,  42,  43,  44,  45,  46,  47,  48,  49,  50],\n",
            "        [ 51,  52,  53,  54,  55,  56,  57,  58,  59,  60],\n",
            "        [ 61,  62,  63,  64,  65,  66,  67,  68,  69,  70],\n",
            "        [ 71,  72,  73,  74,  75,  76,  77,  78,  79,  80],\n",
            "        [ 81,  82,  83,  84,  85,  86,  87,  88,  89,  90],\n",
            "        [ 91,  92,  93,  94,  95,  96,  97,  98,  99, 100]])\n",
            "Here's t_reshaped unsqueezed\n",
            "\n",
            "tensor([[[[  1,   2,   3,   4,   5,   6,   7,   8,   9,  10],\n",
            "          [ 11,  12,  13,  14,  15,  16,  17,  18,  19,  20],\n",
            "          [ 21,  22,  23,  24,  25,  26,  27,  28,  29,  30],\n",
            "          [ 31,  32,  33,  34,  35,  36,  37,  38,  39,  40],\n",
            "          [ 41,  42,  43,  44,  45,  46,  47,  48,  49,  50],\n",
            "          [ 51,  52,  53,  54,  55,  56,  57,  58,  59,  60],\n",
            "          [ 61,  62,  63,  64,  65,  66,  67,  68,  69,  70],\n",
            "          [ 71,  72,  73,  74,  75,  76,  77,  78,  79,  80],\n",
            "          [ 81,  82,  83,  84,  85,  86,  87,  88,  89,  90],\n",
            "          [ 91,  92,  93,  94,  95,  96,  97,  98,  99, 100]]]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#permute usage is when dimensions have a meaning, It does conceptually different this to reshape\n",
        "#remember t_reshaped had dimensions (1,10,10) so if we want to change it to 10 1 10 we switch it the following way, however notice it's different depending on the order of the nth rank\n",
        "tp = t_reshaped.permute(1,0,2)\n",
        "print(tp)\n",
        "tp2 = t_reshaped.permute(2,0,1)\n",
        "print(tp2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fzRxm7YqvBlb",
        "outputId": "fb72e3c1-5cf7-4928-f027-452b3f41f4a3"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[  1,   2,   3,   4,   5,   6,   7,   8,   9,  10]],\n",
            "\n",
            "        [[ 11,  12,  13,  14,  15,  16,  17,  18,  19,  20]],\n",
            "\n",
            "        [[ 21,  22,  23,  24,  25,  26,  27,  28,  29,  30]],\n",
            "\n",
            "        [[ 31,  32,  33,  34,  35,  36,  37,  38,  39,  40]],\n",
            "\n",
            "        [[ 41,  42,  43,  44,  45,  46,  47,  48,  49,  50]],\n",
            "\n",
            "        [[ 51,  52,  53,  54,  55,  56,  57,  58,  59,  60]],\n",
            "\n",
            "        [[ 61,  62,  63,  64,  65,  66,  67,  68,  69,  70]],\n",
            "\n",
            "        [[ 71,  72,  73,  74,  75,  76,  77,  78,  79,  80]],\n",
            "\n",
            "        [[ 81,  82,  83,  84,  85,  86,  87,  88,  89,  90]],\n",
            "\n",
            "        [[ 91,  92,  93,  94,  95,  96,  97,  98,  99, 100]]])\n",
            "tensor([[[  1,  11,  21,  31,  41,  51,  61,  71,  81,  91]],\n",
            "\n",
            "        [[  2,  12,  22,  32,  42,  52,  62,  72,  82,  92]],\n",
            "\n",
            "        [[  3,  13,  23,  33,  43,  53,  63,  73,  83,  93]],\n",
            "\n",
            "        [[  4,  14,  24,  34,  44,  54,  64,  74,  84,  94]],\n",
            "\n",
            "        [[  5,  15,  25,  35,  45,  55,  65,  75,  85,  95]],\n",
            "\n",
            "        [[  6,  16,  26,  36,  46,  56,  66,  76,  86,  96]],\n",
            "\n",
            "        [[  7,  17,  27,  37,  47,  57,  67,  77,  87,  97]],\n",
            "\n",
            "        [[  8,  18,  28,  38,  48,  58,  68,  78,  88,  98]],\n",
            "\n",
            "        [[  9,  19,  29,  39,  49,  59,  69,  79,  89,  99]],\n",
            "\n",
            "        [[ 10,  20,  30,  40,  50,  60,  70,  80,  90, 100]]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##typecasting between numpy and torch tensors\n",
        "It has it's specific uses"
      ],
      "metadata": {
        "id": "SuFnL4przkaY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "##Here's how it's done\n",
        "import numpy as np\n",
        "#numpy -> tensor\n",
        "array = np.arange(1.0,8.0)\n",
        "tensor = torch.from_numpy(array)\n",
        "print(array,tensor)\n",
        "\n",
        "print('\\n')\n",
        "#torch -> numpy\n",
        "testt =  torch.arange(1,10)\n",
        "testa = testt.numpy()\n",
        "print(testt, testa)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "60qdnrGRzjaq",
        "outputId": "57afe0ed-baf8-4bd6-eeaf-34ee8bdf4cee"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1. 2. 3. 4. 5. 6. 7.] tensor([1., 2., 3., 4., 5., 6., 7.], dtype=torch.float64)\n",
            "\n",
            "\n",
            "tensor([1, 2, 3, 4, 5, 6, 7, 8, 9]) [1 2 3 4 5 6 7 8 9]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Reproducibility and seeding"
      ],
      "metadata": {
        "id": "295-bev81ISx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#This is how we seed experiments\n",
        "seed = 42\n",
        "torch.manual_seed(seed)\n",
        "#that's it\n",
        "rand_t  = torch.randn(4,4)\n",
        "rand_t\n",
        "#note that it only lives in the same cell"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RVOcgTcy1Kx3",
        "outputId": "7d856d61-2f31-4a98-fae6-2f6239676abc"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 1.9269,  1.4873,  0.9007, -2.1055],\n",
              "        [ 0.6784, -1.2345, -0.0431, -1.6047],\n",
              "        [-0.7521,  1.6487, -0.3925, -1.4036],\n",
              "        [-0.7279, -0.5594, -0.7688,  0.7624]])"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#this should remain randomn\n",
        "rand_t  = torch.randn(4,4)\n",
        "rand_t"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7BjhqE_n2WVM",
        "outputId": "95033471-d3c1-4a19-de76-763cebcf6eb2"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 1.6423, -0.1596, -0.4974,  0.4396],\n",
              "        [-0.7581,  1.0783,  0.8008,  1.6806],\n",
              "        [ 1.2791,  1.2964,  0.6105,  1.3347],\n",
              "        [-0.2316,  0.0418, -0.2516,  0.8599]])"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Ensuring correct device usage and device agnostic code"
      ],
      "metadata": {
        "id": "y8gkp_sW31x6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#this is device agnostic code.\n",
        "torch.cuda.is_available()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2KsDh42p5jQx",
        "outputId": "2c17b2e5-b41e-4adf-bcec-ab1859478460"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#surprisingly useful, we set a device variable to choose the gpu if available\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
      ],
      "metadata": {
        "id": "wfQ3-7m0336e"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tensor = torch.tensor([1,2,3,4])\n",
        "tensor.device\n",
        "#default is cpu"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FEx5aHyZ4Dlk",
        "outputId": "76bc688a-a99d-4842-a96a-f0b10a68d73a"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cpu')"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tensor = torch.tensor([1,2,3,4], device='cuda')\n",
        "tensor.device\n",
        "#we can change it to gpu"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v8mYbkOV4YSO",
        "outputId": "8dd0c121-b8f8-47c4-b03f-fdb48af5885e"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda', index=0)"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#or move them around using our device variable as convenient\n",
        "tensor = torch.tensor([1,2,3,4])\n",
        "print(tensor.device)\n",
        "gputens = tensor.to(device)\n",
        "print(gputens.device)\n",
        "#'0' is the index of the  gpu in case we are using multiple gpus."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GC6VMJx34iH1",
        "outputId": "d19d8619-cb42-474b-dd4e-2fafaf9ff899"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cpu\n",
            "cuda:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Keep in mind numpy does not work on cpus so here are some methods to use to change tensors into numpy arrays by moving them to the cpu first"
      ],
      "metadata": {
        "id": "SawlINkf5BUF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "gputens.numpy()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "id": "mVtELbAi5BDv",
        "outputId": "bcaeb045-3897-4356-abbd-ec37fb8ccb79"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "can't convert cuda:0 device type tensor to numpy. Use Tensor.cpu() to copy the tensor to host memory first.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2546340165.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mgputens\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m: can't convert cuda:0 device type tensor to numpy. Use Tensor.cpu() to copy the tensor to host memory first."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(gputens.cpu().numpy())\n",
        "#now it works. easy enough\n",
        "gputens.device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ca_CyoaK5LJs",
        "outputId": "24c92e7f-bc8a-496a-f596-fceb7f923118"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1 2 3 4]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda', index=0)"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    }
  ]
}